{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Syntax natürlicher Sprachen, WS 2023/24\n",
    "\n",
    "# 07 - Aufgabenblatt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import Tree\n",
    "from nltk import DependencyGraph\n",
    "from spacy import displacy\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tree_labeled(self, i):\n",
    "    node = self.get_by_address(i)\n",
    "    word, rel = node[\"word\"], node[\"rel\"]\n",
    "    deps = sorted(chain.from_iterable(node[\"deps\"].values()))\n",
    "    return Tree(word + '(' + rel + ')', [self._tree_labeled(dep) for dep in deps]) if deps else word + '(' + rel + ')'\n",
    "\n",
    "def tree_labeled(self):\n",
    "    node = self.root\n",
    "    word, rel = node[\"word\"], node[\"rel\"]\n",
    "    deps = sorted(chain.from_iterable(node[\"deps\"].values()))\n",
    "    return Tree(word+'('+rel+')', [self._tree_labeled(dep) for dep in deps])\n",
    "\n",
    "DependencyGraph._tree_labeled = _tree_labeled\n",
    "DependencyGraph.tree_labeled = tree_labeled\n",
    "\n",
    "def transform_nr_conll(sent_nr):\n",
    "    sent_list = []\n",
    "    for line in list(filter(None, sent_nr.split(\"\\n\"))):\n",
    "        line_list = line.split(); line_list.pop(0); line_list.insert(1,\"_\")\n",
    "        sent_list.append(\" \".join([i for i in line_list[0:]]))\n",
    "    return \"\\n\".join([i for i in sent_list[0:]])\n",
    "\n",
    "def displacy_dep_input(sent):\n",
    "    deps = []\n",
    "    for dep in sent.split('\\n'):\n",
    "        deps.append(dep.split())\n",
    "    deps = [x for x in deps if x]\n",
    "    ex, word_list, arc_list = [], [], []\n",
    "    for index, dep in enumerate(deps):\n",
    "        word_list.append({\"text\": dep[0], \"tag\": \"\"})\n",
    "        line = index+1; head = int(dep[2]); label = dep[3]\n",
    "        if head>line:\n",
    "            start = index; end = head-1; direction = \"left\"\n",
    "        else:\n",
    "            start = head-1; end = index; direction = \"right\"\n",
    "        if(label.lower() != \"root\"):\n",
    "            arc_list.append({\"start\": start, \"end\": end, \"label\": label, \"dir\": direction})\n",
    "    ex.append({\"words\": word_list,\"arcs\": arc_list})\n",
    "    return ex\n",
    "\n",
    "def show_dep_trees(sent_nr,style=1):\n",
    "    sent = transform_nr_conll(sent_nr)\n",
    "    dg = DependencyGraph(sent)\n",
    "    if style == 0 or style == 2:\n",
    "        tree_labeled = dg.tree_labeled()\n",
    "        tree_labeled.pretty_print(unicodelines=True)   \n",
    "    if style == 1 or style == 2:\n",
    "        ex = displacy_dep_input(sent)\n",
    "        html = displacy.render(ex, style=\"dep\", manual=True, options={'distance':100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 1 - Analyse komplexer Satzkonstruktion\n",
    "\n",
    "### a) Sehen Sie sich den folgenden englischen Satz an. Können Sie sich jeweils zwei unterschiedliche Interpretationen vorstellen?\n",
    "\n",
    "- *Visiting relatives can be tiresome.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Erweitern Sie die gegebene Grammatik, so dass linguistisch korrekte Syntaxanalysen beider Interpretationen ausgegeben werden.\n",
    "\n",
    "##### Verwenden Sie `VBG` für *Verb, gerund or present participle* (Penn-Treebank) und `VP-INF` für infinite Satzkonstruktionen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'visiting relatives can be tiresome'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "\n",
    "    VBG -> 'visiting'\n",
    "    N -> 'relatives'\n",
    "    AUX -> 'can'\n",
    "    COP -> 'be'\n",
    "    ADJ -> 'tiresome'\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar)\n",
    "trees = list(parser.parse(sent.split()))\n",
    "if trees: [tree.pretty_print(unicodelines=True) for tree in trees]\n",
    "else: print(f\"no parse found for: {sent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Geben Sie auch die entsprechenden Dependenzstrukturanalysen an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse 1\n",
    "\n",
    "sent_nr = \"\"\"\n",
    "1 x 0 ROOT\n",
    "\"\"\"\n",
    "\n",
    "show_dep_trees(sent_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse 2\n",
    "\n",
    "sent_nr = \"\"\"\n",
    "1 x 0 ROOT\n",
    "\"\"\"\n",
    "\n",
    "show_dep_trees(sent_nr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2 - Analyse komplexer Satzkonstruktion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Schreiben Sie eine CFG, so dass für den folgende Satz eine korrekte Syntaxanalyse ausgegeben wird. Geben Sie auch eine entsprechende Dependenzanalyse an.\n",
    "\n",
    "- *Als ich ankam, habe ich gesehen, dass sie bereits dagewesen sein mussten.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'als ich ankam   habe ich gesehen   dass sie bereits dagewesen sein mussten'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Konstituentenanalyse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring(\n",
    "    \"\"\"\n",
    "\n",
    "    N -> 'ich' | 'alles' | 'sie'\n",
    "    V -> 'ankam' | 'gesehen' | 'dagewesen'\n",
    "    AUX -> | 'habe'| 'sein' | 'mussten'\n",
    "    COMP -> 'als' | 'dass'\n",
    "    ADV -> 'bereits'\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar)\n",
    "trees = list(parser.parse(sent.split()))\n",
    "if trees: [tree.pretty_print(unicodelines=True) for tree in trees]\n",
    "else: print(f\"no parse found for: {sent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependenzanalyse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_nr = \"\"\"\n",
    "1 als \n",
    "2 ich \n",
    "3 ankam \n",
    "4 habe \n",
    "5 ich \n",
    "6 gesehen \n",
    "7 dass \n",
    "8 sie \n",
    "9 bereits \n",
    "10 dagewesen \n",
    "11 sein \n",
    "12 mussten \n",
    "\"\"\"\n",
    "\n",
    "show_dep_trees(sent_nr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
