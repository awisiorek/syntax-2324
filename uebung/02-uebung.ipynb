{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Syntax natürlicher Sprachen, WS 2023/24\n",
    "\n",
    "# 02 - Übung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tree import Tree\n",
    "from nltk.parse.generate import generate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Aufgabe 1 - Ergänzung um Phrasenkategorien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Ergänzen Sie in folgendem Klammerausdruck (aus der vorherigen Übung) die Phrasenkategorie-Label und generieren Sie den entsprechenden Syntaxbaum, indem Sie die Codezelle anschließend ausführen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 ?                              \n",
      "      ┌──────────────────────────┴──────────┐                    \n",
      "      │                                     ?                   \n",
      "      │                ┌────────────────────┴───────┐            \n",
      "      │                ?                            ?           \n",
      "      │          ┌─────┴─────────┐              ┌───┴──────┐     \n",
      "      ?          │               ?              │          ?    \n",
      "      │          │               │              │          │     \n",
      "Fischers_Fritz fischt     die_frischen_Fis     aus     dem_Fluss\n",
      "                                che                             \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree = Tree.fromstring(\"\"\"\n",
    "(?\n",
    "    (? Fischers_Fritz)\n",
    "    (?\n",
    "        (?\n",
    "            fischt\n",
    "            (? die_frischen_Fische)\n",
    "        )\n",
    "        (?\n",
    "            aus\n",
    "            (? dem_Fluss)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Aufgabe 2 - Phrasen und Konstituenten*\n",
    "\n",
    "#### Erläutern Sie am Beispiel des Wortes *Verloren* im folgenden Satz den Unterschied zwischen Konstituente und Phrase.\n",
    "\n",
    "- *Verloren hat er seinen Schlüsselbund zwar noch nie, aber oft genug verlegt.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Aufgabe 3 - Wortarten*\n",
    "\n",
    "### (a) Bestimmen Sie die Wortarten des folgenden Satzes. Geben Sie jeweils das entsprechende Tag aus dem Universal Dependency (http://universaldependencies.org/u/pos/) Tagset an. Sie können für einen Vergleich auch weitere Tagsets verwenden.\n",
    "\n",
    "*Sie gab ihm das neue Buch von Chomsky, aber er zeigte kein Interesse daran.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| *Tagset:* | Sie | gab | ihm | das | neue | Buch | von | Chomsky | aber | er  | zeigte | kein | Interesse | daran |\n",
    "| --- | --- | --- | --- | --- | ---- | ---- | --- | -------- | ---- | --- | ------ | ---- | --------- | ------ |\n",
    "|  | TAG | TAG | TAG | TAG | TAG  | TAG  | TAG | TAG      | TAG  | TAG | TAG    | TAG  | TAG       | TAG    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Vergleichen Sie ihre Tabelle anschließend mit dem Output des Spacy-Taggers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "doc = nlp('Sie gab ihm das neue Buch von Chomsky, aber er zeigte kein Interesse daran.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_string = '{:10s} {:10s} {:10s}'\n",
    "print(format_string.format('Text', 'UD Tag', 'TIGER Tag'))\n",
    "print(format_string.format(*(['==========']*3)))\n",
    "for token in doc:\n",
    "    print(format_string.format(token.text, token.pos_, token.tag_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Verwenden Sie Spacy zur Auflösung unklarer Tagnamen.\n",
    "\n",
    "- `spacy.explain()` ist eine Funktion in der Spacy-Bibliothek, die eine textuelle Erklärung für eine gegebene Spacy-Token-ID oder POS-Tag liefert.\n",
    "\n",
    "- Sie können auch `nltk.help.upenn_tagset()` für zusätzliche Beispiele für die POS-Tags der Penn Treebank verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noun'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('N')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Aufgabe 4 - Distributionsanalysen*\n",
    "\n",
    "#### Mit Hilfe  des NLTK können distributionsäquivalente Wörter gesucht werden, also solche, die in gleichen Kontexten auftreten.\n",
    "\n",
    "#### Betrachten Sie folgenden Aufruf und erläutern Sie.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "little new first good small large great the old other strong young\n",
      "major white second short beautiful a best long\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "text = nltk.Text(word.lower() for word in nltk.corpus.brown.words())\n",
    "text.similar('big')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erläuterung:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Aufgabe 5 - Wortarten im Kontext*\n",
    "\n",
    "#### Betrachten sie folgende Sätze:\n",
    "1. *Er spielt gerne Schach.*\n",
    "2. *Er spielt gut Schach.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diskutieren Sie, ob es sich bei dem Wort *gerne* in Satz 1 um ein Adverb oder ein Adjektiv handelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Um welche Wortart handelt es sich bei dem Lexem *gut* in Satz 2? Diskutieren Sie die Probleme, die hier bei der Wortartenbestimmung auftreten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Welche Wortart könnte man für das Wort gut in Satz 2 vermuten, wenn man Adverbien nicht morphologisch, sondern semantisch charakterisiert (als Wortart, die der Modifizierung des Verbalgeschehens dient)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Aufgabe 6 - Phrasenstrukturbaum\n",
    "\n",
    "#### Geben Sie nun für den Satz aus Aufgabe 1 einen vollständigen Phrasenstrukturbaum inklusive Wortart-Label an:\n",
    "\n",
    "*Fischers Fritz fischt die frischen Fische aus dem Fluss.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " S \n",
      " │  \n",
      "...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree = Tree.fromstring(\"\"\"\n",
    "(S)\n",
    "\"\"\")\n",
    "\n",
    "tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Aufgabe 7 - Eine erste Phrasenstrukturgrammatik*\n",
    "\n",
    "#### (a) Betrachten Sie folgende einfache kontextfreie Grammatik (CFG) und erklären Sie deren Funktionsweise anhand der in der Vorlesung besprochenen Konzepte von CFGs.\n",
    "\n",
    "#### Gehen Sie dabei besonders auf folgende Konzepte ein:\n",
    "\n",
    "- Non-Terminale vs. Terminale\n",
    "- Regelaufbau von CFGS (LHS vs. RHS usw.)\n",
    "- Startsymbol\n",
    "- syntaktische vs. lexikalische Regeln\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> PROPN\n",
    "    VP -> V NP\n",
    "    PROPN -> \"Maria\" | \"Moritz\"\n",
    "    V -> \"kennt\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erklärung durch Kommentare:\n",
    "    S `` -> NP VP #\n",
    "    NP -> PROPN\n",
    "    VP -> V NP\n",
    "    PROPN -> \"Maria\" | \"Moritz\"\n",
    "    V -> \"kennt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Parsen Sie den gegebenen Satz mit Hilfe der Grammatik, indem Sie das folgende Python-Skript ausführen. Erläutern Sie die Funktionsweise des Codes durch Kommentare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP (PROPN Maria)) (VP (V kennt) (NP (PROPN Moritz))))\n",
      "        S             \n",
      "  ┌─────┴────┐         \n",
      "  │          VP       \n",
      "  │     ┌────┴────┐    \n",
      "  NP    │         NP  \n",
      "  │     │         │    \n",
      "PROPN   V       PROPN \n",
      "  │     │         │    \n",
      "Maria kennt     Moritz\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sent = \"Maria kennt Moritz\"\n",
    "\n",
    "parser = nltk.ChartParser(grammar)\n",
    "for tree in parser.parse(sent.split()):\n",
    "    print(tree)\n",
    "    tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Überlegen Sie zunächst, wie viele Sätze von dieser Grammatik generiert werden können, bevor Sie den folgenden Codeblock ausführen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in generate(grammar, depth=5):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 8 - Erweiterung Phrasenstrukturgrammatik\n",
    "#### Erweitern Sie die Grammatik aus der vorherigen Aufgabe um syntaktische sowie lexikalische Regeln für eine adverbiale Ergänzung mit *(sehr) gut*.\n",
    "\n",
    "#### Testen Sie dazu mit untenstehenden Beispielsätzen, ob Ihre Grammatik den Satz ableitet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [\n",
    "    \"Maria kennt Moritz gut\",\n",
    "    \"Maria kennt Moritz sehr gut\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> PROPN\n",
    "    VP -> V NP\n",
    "    PROPN -> \"Maria\" | \"Moritz\"\n",
    "    V -> \"kennt\"\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar)\n",
    "for sent in sents:\n",
    "    trees = list(parser.parse(sent.split()))\n",
    "    if trees: [tree.pretty_print(unicodelines=True) for tree in trees]\n",
    "    else: print(\"no parse found for: \" + sent) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
